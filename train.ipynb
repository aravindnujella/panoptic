{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: combien visualize and iresnet\n",
    "# write code for forward pass of the model\n",
    "# loss code\n",
    "# training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T14:54:01.640587Z",
     "start_time": "2018-10-03T14:54:01.327601Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "import os\n",
    "import json\n",
    "import os.path\n",
    "import colorsys\n",
    "\n",
    "\n",
    "inf = float('inf')\n",
    "nan = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T14:54:46.019970Z",
     "start_time": "2018-10-03T14:54:46.013566Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/aravind/dataset/\"\n",
    "ann_dir = data_dir + \"annotations/panoptic/\"\n",
    "\n",
    "train_img_dir = data_dir + \"train2017/\"\n",
    "train_seg_dir = ann_dir + \"panoptic_train2017/\"\n",
    "train_ann_json = ann_dir + \"panoptic_train2017.json\"\n",
    "\n",
    "val_img_dir = data_dir + \"val2017/\"\n",
    "val_seg_dir = ann_dir + \"panoptic_val2017/\"\n",
    "val_ann_json = ann_dir + \"panoptic_val2017.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T14:54:53.679915Z",
     "start_time": "2018-10-03T14:54:53.428871Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(val_ann_json,\"r\") as f:\n",
    "    val_ann = json.load(f)\n",
    "# with open(train_ann_json,\"r\") as f:\n",
    "#     train_ann = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T14:55:03.800758Z",
     "start_time": "2018-10-03T14:55:03.737975Z"
    }
   },
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "\n",
    "\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 16\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    NUM_WORKERS = 16\n",
    "    PIN_MEMORY = True\n",
    "    VALIDATION_STEPS = 20\n",
    "\n",
    "    CAT_NAMES = ['BG'] + [\n",
    "        'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',\n",
    "        'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'banner',\n",
    "        'blanket', 'bridge', 'cardboard', 'counter', 'curtain', 'door-stuff',\n",
    "        'floor-wood', 'flower', 'fruit', 'gravel', 'house', 'light',\n",
    "        'mirror-stuff', 'net', 'pillow', 'platform', 'playingfield',\n",
    "        'railroad', 'river', 'road', 'roof', 'sand', 'sea', 'shelf', 'snow',\n",
    "        'stairs', 'tent', 'towel', 'wall-brick', 'wall-stone', 'wall-tile',\n",
    "        'wall-wood', 'water-other', 'window-blind', 'window-other',\n",
    "        'tree-merged', 'fence-merged', 'ceiling-merged', 'sky-other-merged',\n",
    "        'cabinet-merged', 'table-merged', 'floor-other-merged',\n",
    "        'pavement-merged', 'mountain-merged', 'grass-merged', 'dirt-merged',\n",
    "        'paper-merged', 'food-other-merged', 'building-other-merged',\n",
    "        'rock-merged', 'wall-other-merged', 'rug-merged'\n",
    "    ]\n",
    "    CAT_IDS = [0] + [\n",
    "        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
    "        22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
    "        43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
    "        62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84,\n",
    "        85, 86, 87, 88, 89, 90, 92, 93, 95, 100, 107, 109, 112, 118, 119, 122,\n",
    "        125, 128, 130, 133, 138, 141, 144, 145, 147, 148, 149, 151, 154, 155,\n",
    "        156, 159, 161, 166, 168, 171, 175, 176, 177, 178, 180, 181, 184, 185,\n",
    "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
    "        200\n",
    "    ]\n",
    "    IGNORE_CAT_NAMES = ['BG']\n",
    "    MEAN_PIXEL = np.array(\n",
    "        [0.485, 0.456, 0.406], dtype=np.float32).reshape(1, 1, -1)\n",
    "    STD_PIXEL = np.array(\n",
    "        [0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 1, -1)\n",
    "\n",
    "    IMPULSE_SIZE = (9, 9)\n",
    "    MIN_STUFF_AREA = 10 * 10\n",
    "\n",
    "    def __init__(self):\n",
    "        self.WIDTH = 32 * 14\n",
    "        self.HEIGHT = 32 * 14\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT, 3)\n",
    "        # 133 + 1 in panoptic\n",
    "        self.NUM_CATS = len(self.CAT_NAMES)\n",
    "        self.IGNORE_CAT_IDS = [\n",
    "            self.CAT_NAMES.index(c) for c in self.IGNORE_CAT_NAMES\n",
    "        ]\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "class CocoDetection(data.Dataset):\n",
    "    def __init__(self, img_dir, seg_dir, ann, config):\n",
    "        self.img_dir = img_dir\n",
    "        self.seg_dir = seg_dir\n",
    "        self.coco_data = self.index_annotations(ann)\n",
    "        self.config = config\n",
    "        self.catMap = self.build_cat_map()\n",
    "\n",
    "    def index_annotations(self, ann):\n",
    "        # create map with coco image index as key\n",
    "        d = {}\n",
    "        for i in ann['annotations']:\n",
    "            coco_index = i['image_id']\n",
    "            d[coco_index] = {\n",
    "                'segments_info': i['segments_info'],\n",
    "                'segments_file': i['file_name'],\n",
    "                'image_id': i['image_id']\n",
    "            }\n",
    "        for i in ann['images']:\n",
    "            coco_index = i['id']\n",
    "            image_file = i['file_name']\n",
    "            d[coco_index]['image_file'] = image_file\n",
    "\n",
    "        return list(d.values())\n",
    "\n",
    "    # coco category ids remapped to contigous range(133+1)\n",
    "    def build_cat_map(self):\n",
    "        config = self.config\n",
    "        coco_cat_ids = config.CAT_IDS\n",
    "        catMap = {}\n",
    "        for i in range(config.NUM_CATS):\n",
    "            catMap[coco_cat_ids[i]] = i\n",
    "        return catMap\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        try:\n",
    "            # 0. read coco data as is; if no instances of required criteria then\n",
    "            # return None and filter in collate\n",
    "            data = self.load_data(index)\n",
    "\n",
    "            # 1. remove unwanted data\n",
    "            # 2. fixed resolution.\n",
    "            # 3. split stuff islands into different instances\n",
    "            # 4. Data Augmentation: skipped for now\n",
    "            data = self.standardize_data(*data)\n",
    "\n",
    "            # 4. Target generation:\n",
    "            return self.generate_targets(*data)\n",
    "\n",
    "        except:\n",
    "            print(\"problem loading image index: %d\" % index)\n",
    "            return None\n",
    "\n",
    "    def load_data(self, index):\n",
    "        coco_data = self.coco_data\n",
    "        config = self.config\n",
    "\n",
    "        ignore_cat_ids = config.IGNORE_CAT_IDS\n",
    "\n",
    "        ann = coco_data[index]\n",
    "        image_id = ann['image_id']\n",
    "        segments_info = ann['segments_info']\n",
    "        segments_file = ann['segments_file']\n",
    "        image_file = ann['image_file']\n",
    "        print(image_id)\n",
    "        img = Image.open(os.path.join(self.img_dir, image_file)).convert('RGB')\n",
    "        img = np.array(img)\n",
    "\n",
    "        instance_masks = []\n",
    "        cat_ids = []\n",
    "\n",
    "        coco_seg = Image.open(os.path.join(self.seg_dir,\n",
    "                                           segments_file)).convert('RGB')\n",
    "        coco_seg = np.array(coco_seg, dtype=np.uint8)\n",
    "        seg_id = self.rgb2id(coco_seg)\n",
    "\n",
    "        ignore_cat_ids = np.array(config.IGNORE_CAT_IDS)\n",
    "        for s in segments_info:\n",
    "            mask = np.where(seg_id == s['id'], 1, 0)\n",
    "            iscrowd = s['iscrowd']\n",
    "            cat_id = self.catMap[s['category_id']]\n",
    "            if (s['iscrowd'] != 1) and (cat_id not in ignore_cat_ids):\n",
    "                instance_masks.append(mask)\n",
    "                cat_ids.append(self.catMap[s['category_id']])\n",
    "\n",
    "        cat_ids = np.array(cat_ids)\n",
    "        instance_masks = np.array(instance_masks)\n",
    "\n",
    "        return img, instance_masks, cat_ids\n",
    "\n",
    "    def standardize_data(self, img, instance_masks, cat_ids):\n",
    "        instance_masks, cat_ids = self.split_stuff_islands(\n",
    "            instance_masks, cat_ids)\n",
    "        img, instance_masks = self.resize_data(img, instance_masks)\n",
    "\n",
    "        # img, instance_masks, cat_ids = self.data_augment(img, instance_masks, cat_ids)\n",
    "        return img, instance_masks, cat_ids\n",
    "\n",
    "    def generate_targets(self, img, instance_masks, cat_ids):\n",
    "        from scipy.ndimage import convolve\n",
    "\n",
    "        impulses = []\n",
    "        for mask in instance_masks:\n",
    "            # single size lp filter, not multi scale targetting\n",
    "            lp_filter = np.ones((13, 13))\n",
    "            # convolve and check locations where the conv is maximum\n",
    "            smooth_mask = convolve(mask, lp_filter, mode='constant', cval=0.0)\n",
    "            idx = np.where(smooth_mask == np.max(smooth_mask))\n",
    "            p, q = random.choice(list(zip(idx[0], idx[1])))\n",
    "\n",
    "            iw, ih = self.config.IMPULSE_SIZE\n",
    "\n",
    "            impulse = np.zeros_like(mask)\n",
    "            impulse[p - iw:p + iw, q - ih:q + ih] = 1\n",
    "            impulses.append(impulse)\n",
    "\n",
    "        impulses = np.array(impulses)\n",
    "        # work this shit out\n",
    "        # place an impulse around peak response\n",
    "        # => one impulse/instance\n",
    "        # write custom collate %%later\n",
    "        return img, impulses, instance_masks, cat_ids\n",
    "\n",
    "    def rgb2id(self, color):\n",
    "        return color[:, :,\n",
    "                     0] + 256 * color[:, :, 1] + 256 * 256 * color[:, :, 2]\n",
    "\n",
    "    def split_stuff_islands(self, instance_masks, cat_ids):\n",
    "        from scipy.ndimage import label, convolve\n",
    "\n",
    "        thing_idx = np.nonzero(cat_ids <= 80)\n",
    "        stuff_idx = np.nonzero(cat_ids > 80)\n",
    "\n",
    "        thing_ids = cat_ids[thing_idx]\n",
    "        stuff_ids = cat_ids[stuff_idx]\n",
    "        thing_masks = instance_masks[thing_idx]\n",
    "        stuff_masks = instance_masks[stuff_idx]\n",
    "\n",
    "        # this is to merge nearby stuff islands\n",
    "        # that might be split due to noisy annotation\n",
    "        lp_filter = np.ones((5, 5))\n",
    "\n",
    "        for mask, stuff_id in zip(stuff_masks, stuff_ids):\n",
    "            smooth_mask = convolve(mask, lp_filter, mode='constant', cval=0.0)\n",
    "            smooth_mask = np.where(smooth_mask > 12, 1, 0)\n",
    "\n",
    "            labelled_islands, num_islands = label(\n",
    "                smooth_mask, structure=np.ones((3, 3)))\n",
    "            islands = []\n",
    "            island_cat_ids = []\n",
    "            for i in range(num_islands):\n",
    "                island = np.where(labelled_islands == i + 1, 1, 0)\n",
    "                if np.sum(island) > self.config.MIN_STUFF_AREA:\n",
    "                    islands.append(island)\n",
    "                    island_cat_ids.append(stuff_id)\n",
    "            islands = np.array(islands)\n",
    "            island_cat_ids = np.array(island_cat_ids)\n",
    "            thing_masks = np.concatenate([thing_masks, islands], 0)\n",
    "            thing_ids = np.concatenate([thing_ids, island_cat_ids], 0)\n",
    "\n",
    "        return thing_masks, thing_ids\n",
    "\n",
    "    def resize_data(self, img, instance_masks):\n",
    "        config = self.config\n",
    "\n",
    "        w, h = config.WIDTH, config.HEIGHT\n",
    "        img = self.resize_image(img, (w, h), \"RGB\")\n",
    "        instance_masks = np.array(\n",
    "            [self.resize_image(m, (w, h), \"L\") for m in instance_masks])\n",
    "\n",
    "        return img, instance_masks\n",
    "\n",
    "    def resize_image(self, img, size, mode):\n",
    "        interpolation = {\"RGB\": Image.BICUBIC, \"L\": Image.NEAREST}[mode]\n",
    "        img_obj = Image.fromarray(img.astype(np.uint8), mode)\n",
    "        img_obj.thumbnail(size, interpolation)\n",
    "\n",
    "        (w, h) = img_obj.size\n",
    "        padded_img = Image.new(mode, size, \"black\")\n",
    "        padded_img.paste(img_obj, ((size[0] - w) // 2, (size[1] - h) // 2))\n",
    "\n",
    "        return np.array(padded_img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProposalConfig()\n",
    "val_dataset = CocoDetection(val_img_dir, val_seg_dir, val_ann, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:33.309928Z",
     "start_time": "2018-10-22T11:28:32.786458Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import model\n",
    "import pan_loader\n",
    "import base_config\n",
    "import loss_functions as L\n",
    "\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:33.316217Z",
     "start_time": "2018-10-22T11:28:33.312524Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/aravind/dataset/\"\n",
    "ann_dir = data_dir + \"annotations/panoptic/\"\n",
    "\n",
    "train_img_dir = data_dir + \"train2017/\"\n",
    "train_seg_dir = ann_dir + \"panoptic_train2017/\"\n",
    "train_ann_json = ann_dir + \"panoptic_train2017.json\"\n",
    "\n",
    "val_img_dir = data_dir + \"val2017/\"\n",
    "val_seg_dir = ann_dir + \"panoptic_val2017/\"\n",
    "val_ann_json = ann_dir + \"panoptic_val2017.json\"\n",
    "\n",
    "train_img_dir = val_img_dir \n",
    "train_seg_dir = val_seg_dir \n",
    "train_ann_json = val_ann_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:33.740127Z",
     "start_time": "2018-10-22T11:28:33.318434Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(val_ann_json,\"r\") as f:\n",
    "    val_ann = json.load(f)\n",
    "with open(train_ann_json,\"r\") as f:\n",
    "    train_ann = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:33.744893Z",
     "start_time": "2018-10-22T11:28:33.742259Z"
    }
   },
   "outputs": [],
   "source": [
    "config = base_config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:33.767538Z",
     "start_time": "2018-10-22T11:28:33.746651Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = pan_loader.get_loader(train_img_dir, train_seg_dir, train_ann, config)\n",
    "val_loader = pan_loader.get_loader(val_img_dir, val_seg_dir, val_ann, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:39.253412Z",
     "start_time": "2018-10-22T11:28:33.769749Z"
    }
   },
   "outputs": [],
   "source": [
    "net = model.hgmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:39.291700Z",
     "start_time": "2018-10-22T11:28:39.257659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69912050 69912050\n",
      "[{'params': <generator object Module.parameters at 0x7fe3e7f29620>, 'lr': 0.01, 'momentum': 0.9}]\n"
     ]
    }
   ],
   "source": [
    "def set_trainable(module,state):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = state\n",
    "\n",
    "set_trainable(net,False)\n",
    "\n",
    "set_trainable(net.mb0,True)\n",
    "set_trainable(net.mb1,True)\n",
    "set_trainable(net.cb,True)\n",
    "\n",
    "set_trainable(net.iresnet0, True)\n",
    "set_trainable(net.iresnet1, True)\n",
    "\n",
    "# for name,child in net.iresnet0.named_children():\n",
    "#     if name[:-1] == \"layer\":\n",
    "#         [set_trainable(s.ignore_filters,True) for s in child[::2]]\n",
    "#         [set_trainable(s.copy_filters,True) for s in child[::2]]\n",
    "\n",
    "param_lr = []\n",
    "param_lr.append({'params': net.mb0.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "param_lr.append({'params': net.mb1.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "param_lr.append({'params': net.cb.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "\n",
    "# for name,child in net.iresnet0.named_children():\n",
    "#     if name[:-1] == \"layer\":\n",
    "#         for s in child[::2]:\n",
    "#             lr = 0\n",
    "#             if int(name[-1]) > 0:\n",
    "#                 lr = 1e-3\n",
    "#             else:\n",
    "#                 lr = 0\n",
    "#             param_lr.append({'params':s.ignore_filters.parameters(),'lr':lr,'momentum':0.9})\n",
    "#             param_lr.append({'params':s.copy_filters.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "\n",
    "param_lr = [{'params':net.parameters(),'lr':1e-2, 'momentum':0.9}]\n",
    "net_size = sum([i.numel() for i in net.parameters()])\n",
    "trainable_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "trainable_size = sum([i.numel() for i in trainable_params])\n",
    "print(net_size,trainable_size)\n",
    "print(param_lr)\n",
    "optimizer = optim.SGD(param_lr)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=1, patience=10, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=100, min_lr=1e-2, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:42.122015Z",
     "start_time": "2018-10-22T11:28:39.294143Z"
    }
   },
   "outputs": [],
   "source": [
    "# net = nn.DataParallel(net, device_ids=[0,1])\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T11:28:52.212075Z",
     "start_time": "2018-10-22T11:28:42.125223Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[ 22 131] [131]\n",
      "[1]\n",
      "[17 42] [42]\n",
      "[3]\n",
      "[  1   1  21 117 118 120 127 130 132] [117]\n",
      "[6]\n",
      "[  1   1   1  33 101 118 124 127 132] [124]\n",
      "[4]\n",
      "[ 16  62 112 121 123 128 132 133] [123]\n",
      "[3]\n",
      "[ 42  55  61  61 122 132] [61]\n",
      "[4]\n",
      "[  1   3  11 101 124] [124]\n",
      "[0]\n",
      "[  1  54  57  87 122 123 132] [1]\n",
      "[14]\n",
      "[  1   1   1  27  40  54  54  61  61 110 113 116 122 124 128 129] [128]\n",
      "[11]\n",
      "[ 21  21  21  21  21  21  21  21  21  21 100 131] [131]\n",
      "[10]\n",
      "[ 40  40  40  40  40  40  40  40  62 123 132] [132]\n",
      "[6]\n",
      "[  1   6  10  10  10 117 130 132] [130]\n",
      "[13]\n",
      "[ 40  40  62  72  85  86  87  93  94 112 119 121 123 132] [132]\n",
      "[0]\n",
      "[14 16 16 88 94] [14]\n",
      "[tensor([131], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.8414, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([117], device='cuda:0')]\n",
      "[2]\n",
      "[ 43  44 129] [129]\n",
      "[3]\n",
      "[  1   1  42  60  60  82 116 122 123 128] [60]\n",
      "[2]\n",
      "[ 21  21 117 126] [117]\n",
      "[4]\n",
      "[ 75  83 104 117 120 127 130] [120]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward1>) tensor(16.0190, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([131], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.4113, device='cuda:0', grad_fn=<MeanBackward1>) tensor(3.2952, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[19]\n",
      "[  1   1   1   1   1   1   1   3   3   8   8  10  10  10 101 117 120 124\n",
      " 126 130] [130]\n",
      "[16]\n",
      "[  1   1   1  25  26  26  27  37  46  46  53  53  53  93 101 112 124 128\n",
      " 129 132] [124]\n",
      "[tensor([132], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9833, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[13]\n",
      "[  1   1   1   1   1   1   1   1   1   1   4 101 118 126] [126]\n",
      "[25]\n",
      "[  1  42  57  63  66  66  74  74  74  74  74  74  74  74  74  74  74  74\n",
      "  81  87  93 105 119 122 123 128 132] [128]\n",
      "[14]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1  14  14  14  36  57\n",
      "  57  57  57  57  57  98 120 130 132] [14]\n",
      "[26]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1   4   4   4   4  14\n",
      "  14  14  14  18  18  18  18  81  92  98 101 117 125 126] [92]\n",
      "[2]\n",
      "[16 16 58 66 66 82] [58]\n",
      "[tensor([60], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.1101, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([1], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.1884, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[27]\n",
      "[3]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1   8   8  18  18  18\n",
      "  18  18  18  18  18  18  18  18  91 117 120 126][  5  81 117 120] [120]\n",
      " [117]\n",
      "[6]\n",
      "[  1   1   3  37 117 118 124 132] [124]\n",
      "[3]\n",
      "[  7   7 123 130] [130]\n",
      "[tensor([117], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward1>) tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([123], device='cuda:0')]\n",
      "[5]\n",
      "[  3   8   8  14 117 127 130] [127]\n",
      "[11]\n",
      "[  1   1   1   1   1  23  23  23  23  24  93 117 118 119 120 127 131] [117]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2765, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([61], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.1460, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[2]\n",
      "[  1  28 132] [132]\n",
      "[3]\n",
      "[  1   3   3   7 101 117 118 120 126] [7]\n",
      "[0]\n",
      "[  4   4  25  27 102 117 118 120 126] [4]\n",
      "[8]\n",
      "[  1   2  14  17 101 116 117 124 130] [130]\n",
      "[8]\n",
      "[  1  59  59  59  59  64  65  84 117 122 123 128] [117]\n",
      "[tensor([92], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9481, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([130], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9703, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[6]\n",
      "[  1  11  35  89 101 117 126] [126]\n",
      "[10]\n",
      "[  1   1   1   1   1  31  31  31  31  92 106 117 125] [106]\n",
      "[16]\n",
      "[  1   1   1   1   1   1  27  27  27  68  68  68  68  68 105 110 116 119\n",
      " 132] [116]\n",
      "[tensor([128], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.8476, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([42], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.8613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[21]\n",
      "[  1   1   1   1   1  40  42  42  42  43  43  43  44  44  54  54  54  54\n",
      "  57  61  61 132] [132]\n",
      "[2]\n",
      "[ 75  93 120 130] [120]\n",
      "[tensor([128], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8755, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.7779, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([132], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.6738, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[9]\n",
      "[  1   1   1   1   1   1  11  27 101 124] [124]\n",
      "[tensor([124], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.5197, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9728, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([117], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.2547, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[2]\n",
      "[ 21  21 117 120 126] [117]\n",
      "[tensor([130], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.1841, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([14], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.8448, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([58], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward1>) tensor(7.5847, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([120], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.4308, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9953, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([126], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9214, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([4], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9145, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([14], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.7740, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([120], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.8263, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([7], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9484, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([132], device='cuda:0')]\n",
      "[12]\n",
      "[  1   1  25  42  42  54  54  54  59  61 122 128 132] [132]\n",
      "[12]\n",
      "[  1   1   1   1   1   1  21  21  21  21  21  21 100 117] [100]\n",
      "[13]\n",
      "[ 57  58  61  74  74  74  74  76  76  76  89  96 122 132] [132]\n",
      "[2]\n",
      "[47 47 61] [61]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.5627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([129], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.4878, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9652, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[8]\n",
      "[ 24  24  87 107 116 118 119 123 132] [132]\n",
      "[tensor([124], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.7272, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([127], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.0472, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[6]\n",
      "[  1   1  25  25  31  31 106 117 120 125] [106]\n",
      "[26]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1  14  14  17  19  19\n",
      "  19  19  19  27  95 117 118 120 126] [126]\n",
      "[tensor([124], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward1>) tensor(3.9097, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([124], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward1>) tensor(2.0233, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[0]\n",
      "[ 16  57  66  66  74  74  74  74  74  74  74  74  74  74  74  74  74  78\n",
      "  87 121 122 128 132] [16]\n",
      "[8]\n",
      "[  1   1   1   1   1   1   1   3   6 101 117 120 130 132] [6]\n",
      "[14]\n",
      "[ 42  64  74  74  74  74  74  74  84 105 113 122 123 128 132] [132]\n",
      "[16]\n",
      "[  1  33  33  33  33  33  33  33  33  33  33  33  33  39  98 117 118 120] [118]\n",
      "[31]\n",
      "[ 40  40  40  57  58  59  60  61  63  68  69  73  74  74  74  74  74  74\n",
      "  74  74  74  74  74  74  86  88  93 119 121 122 128 132 133] [132]\n",
      "[tensor([116], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8820, device='cuda:0', grad_fn=<MeanBackward1>) tensor(14.3823, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([117], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.0510, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([106], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.0856, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([130], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.9902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([117], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward1>) tensor(2.5929, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([130], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward1>) tensor(11.4427, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[6]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1  25  27  27  27  27\n",
      "  27  27  42  42  42  42  42  45  45  45  45  45  45  46  46  46  46  46\n",
      "  46  46  46  46  57  57  61  61  61  87 113 119 123 132] [1]\n",
      "[1]\n",
      "[  5 120] [120]\n",
      "[tensor([132], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.3361, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([132], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.3704, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[0]\n",
      "[ 62  74 112 123 128] [62]\n",
      "[4]\n",
      "[ 40  42  43  44  46  61 122] [46]\n",
      "[tensor([126], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.7604, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([100], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.1158, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([6], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.4638, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.0752, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([124], device='cuda:0')]\n",
      "[10]\n",
      "[  1   9   9   9   9  26  91  92 104 117 120 124 125 130 132] [120]\n",
      "[1]\n",
      "[  1   3  17 101 117 120] [3]\n",
      "[0]\n",
      "[  1  80 112 116 132] [1]\n",
      "[0]\n",
      "[  1  80  86 105 123] [1]\n",
      "[0]\n",
      "[19]\n",
      "[  7  91 117 120 126 130] [7]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1  33  39  81 107 109\n",
      " 118 132] [132]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.3984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([120], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.6359, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[2]\n",
      "[ 62 112 123] [123]\n",
      "[tensor([1], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.0074, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([126], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward1>) tensor(3.4627, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[2]\n",
      "[  1  38 104 120] [104]\n",
      "[28]\n",
      "[  1   1   1  42  47  47  47  47  47  47  47  47  47  47  47  47  47  48\n",
      "  48  48  48  50  50  52  52  57  61  82  90 123 130] [90]\n",
      "[tensor([117], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.6182, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([132], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward1>) tensor(3.2521, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[16]\n",
      "[  1   1   1   1   1   1   1   1   3   3   6  27  27 101 117 118 120 124\n",
      " 126 130] [120]\n",
      "[15]\n",
      "[  1   1   1   1   1   9  11  11  25  27  27 101 117 120 124 126 127 130] [126]\n",
      "[10]\n",
      "[  1   1   1   1   1   1  25  34  34 117 120 126 130] [120]\n",
      "[tensor([132], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward1>) tensor(1.8096, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([118], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward1>) tensor(10.4075, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\n",
      "[  1   1   1   1   1   1   1   1   1   1   1   1   1 120 124 130] [130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-15:\n",
      "Process Process-8:\n",
      "Process Process-14:\n",
      "Process Process-4:\n",
      "Process Process-11:\n",
      "Process Process-13:\n",
      "Process Process-1:\n",
      "Process Process-16:\n",
      "Process Process-10:\n",
      "Process Process-12:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-6:\n",
      "Process Process-9:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([106], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.7727, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "[tensor([61], device='cuda:0')]\n",
      "torch.Size([1, 1, 448, 448]) torch.Size([1, 1, 448, 448]) torch.Size([1]) torch.Size([1, 134])\n",
      "tensor(0.2685, device='cuda:0', grad_fn=<MeanBackward1>) tensor(4.4871, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 110, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fe3ef87fa90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 399, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 378, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 411, in _recv_bytes\n",
      "    return self._recv(size)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 27320) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b339d0fe81e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ckpt = utils.Checkpoint(iters_per_epoch=60, model_dir=\"./models/\", model_name=\"first\")\n",
    "\n",
    "for i, data in enumerate(train_loader,0):\n",
    "#     print(\"batch %d:\"%i)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    images, impulses, instance_masks, cat_ids = utils.cudify_data(data)\n",
    "    print(cat_ids)\n",
    "    del(data)\n",
    "    outs = net([images,impulses])\n",
    "    del(images, impulses)\n",
    "    loss = L.loss_criterion1(outs, [instance_masks, cat_ids])\n",
    "    del(instance_masks, cat_ids, outs)\n",
    "    ckpt.update(loss.data, net)\n",
    "    loss.backward()\n",
    "    del(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

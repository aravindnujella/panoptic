{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "import os\n",
    "import json\n",
    "import os.path\n",
    "import colorsys\n",
    "\n",
    "\n",
    "inf = float('inf')\n",
    "nan = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/aravind/dataset/\"\n",
    "ann_dir = data_dir + \"annotations/panoptic/\"\n",
    "cat_file = ann_dir + \"panoptic_coco_categories.json\"\n",
    "\n",
    "train_img_dir = data_dir + \"train2017/\"\n",
    "train_seg_dir = ann_dir + \"panoptic_train2017/\"\n",
    "train_ann_json = ann_dir + \"panoptic_train2017.json\"\n",
    "\n",
    "val_img_dir = data_dir + \"val2017/\"\n",
    "val_seg_dir = ann_dir + \"panoptic_val2017/\"\n",
    "val_ann_json = ann_dir + \"panoptic_val2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_ann_json,\"r\") as f:\n",
    "    val_ann = json.load(f)\n",
    "with open(train_ann_json,\"r\") as f:\n",
    "    train_ann = json.load(f)\n",
    "with open(cat_file,\"r\") as f:\n",
    "    cat_list = json.load(f)\n",
    "coco_cats = {c['id']: c for c in cat_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 16\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    NUM_WORKERS = 16\n",
    "    PIN_MEMORY = True\n",
    "    VALIDATION_STEPS = 20\n",
    "    # including bg\n",
    "    NUM_CLASSES = 81\n",
    "\n",
    "    MEAN_PIXEL = np.array(\n",
    "        [0.485, 0.456, 0.406], dtype=np.float32).reshape(1, 1, -1)\n",
    "    STD_PIXEL = np.array(\n",
    "        [0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 1, -1)\n",
    "    GRID_SHAPE = 6\n",
    "    IMPULSE_SHAPE = (32, 32)\n",
    "    MIN_PIXELS = 1\n",
    "    MIN_INTERSECTION = 1\n",
    "    def __init__(self):\n",
    "        self.WIDTH = 32 * self.GRID_SHAPE\n",
    "        self.HEIGHT = 32 * self.GRID_SHAPE\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT, 3)\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(data.Dataset):\n",
    "    def __init__(self, img_dir, ann_file, config):\n",
    "        self.img_dir = img_dir\n",
    "        self.coco = self.index_coco(ann_file)\n",
    "        self.config = config\n",
    "        self.catMap = self.build_class_map()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2id(color):\n",
    "    return color[:, :, 0] + 256 * color[:, :, 1] + 256 * 256 * color[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(val_ann['annotations'][0].keys())\n",
    "# print(val_ann.keys())\n",
    "# print(val_ann['categories'][:3])\n",
    "# print(coco_cats)\n",
    "# print(val_ann['info'])\n",
    "# print(val_ann['annotations'][0]['image_id'])\n",
    "# print(val_ann[\"annotations\"][0])\n",
    "# print(val_ann['images'])\n",
    "ann = val_ann[\"annotations\"][0]\n",
    "Image.open(val_dir+ann['file_name'].replace('.png','.jpg')).show()\n",
    "# Image.open(val_seg+ann['file_name']).show()\n",
    "# print(coco_cats[23])\n",
    "segmentation = np.array(Image.open(val_seg+ann['file_name']),dtype=np.uint8)\n",
    "segmentation_id = rgb2id(segmentation)\n",
    "for segment_info in ann['segments_info']:\n",
    "    mask = (segmentation_id==segment_info['id'])\n",
    "    Image.fromarray((mask*255).astype(np.uint8),\"L\").show()\n",
    "print(val_ann['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = np.random.choice(val_ann['annotations'])\n",
    "Image.open()\n",
    "for i in range(len(val_ann['annotations'])):\n",
    "    ann = val_ann['annotations'][i]\n",
    "    image_info = val_ann[\"images\"][i]\n",
    "    print(image_info['id'])\n",
    "    print(ann['image_id'])\n",
    "    print(i)\n",
    "# for image_info in val_ann[\"images\"]:\n",
    "#     if image_info['id'] == ann['image_id']:\n",
    "#         print(image_info['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

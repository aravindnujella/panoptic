{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T10:56:35.954336Z",
     "start_time": "2018-08-18T10:56:35.640463Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "import os\n",
    "import json\n",
    "import os.path\n",
    "import colorsys\n",
    "\n",
    "\n",
    "inf = float('inf')\n",
    "nan = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T10:56:35.960865Z",
     "start_time": "2018-08-18T10:56:35.956886Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/aravind/dataset/\"\n",
    "ann_dir = data_dir + \"annotations/panoptic/\"\n",
    "\n",
    "train_img_dir = data_dir + \"train2017/\"\n",
    "train_seg_dir = ann_dir + \"panoptic_train2017/\"\n",
    "train_ann_json = ann_dir + \"panoptic_train2017.json\"\n",
    "\n",
    "val_img_dir = data_dir + \"val2017/\"\n",
    "val_seg_dir = ann_dir + \"panoptic_val2017/\"\n",
    "val_ann_json = ann_dir + \"panoptic_val2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T10:56:42.752571Z",
     "start_time": "2018-08-18T10:56:36.615013Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(val_ann_json,\"r\") as f:\n",
    "    val_ann = json.load(f)\n",
    "with open(train_ann_json,\"r\") as f:\n",
    "    train_ann = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T10:56:42.791607Z",
     "start_time": "2018-08-18T10:56:42.754905Z"
    }
   },
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "\n",
    "\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 16\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    NUM_WORKERS = 16\n",
    "    PIN_MEMORY = True\n",
    "    VALIDATION_STEPS = 20\n",
    "\n",
    "    CLASS_NAMES = ['BG'] + [\n",
    "        'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'banner',\n",
    "        'blanket', 'bridge', 'cardboard', 'counter', 'curtain', 'door-stuff',\n",
    "        'floor-wood', 'flower', 'fruit', 'gravel', 'house', 'light',\n",
    "        'mirror-stuff', 'net', 'pillow', 'platform', 'playingfield',\n",
    "        'railroad', 'river', 'road', 'roof', 'sand', 'sea', 'shelf', 'snow',\n",
    "        'stairs', 'tent', 'towel', 'wall-brick', 'wall-stone', 'wall-tile',\n",
    "        'wall-wood', 'water-other', 'window-blind', 'window-other',\n",
    "        'tree-merged', 'fence-merged', 'ceiling-merged', 'sky-other-merged',\n",
    "        'cabinet-merged', 'table-merged', 'floor-other-merged',\n",
    "        'pavement-merged', 'mountain-merged', 'grass-merged', 'dirt-merged',\n",
    "        'paper-merged', 'food-other-merged', 'building-other-merged',\n",
    "        'rock-merged', 'wall-other-merged', 'rug-merged'\n",
    "    ]\n",
    "    CAT_IDS = [0] + [\n",
    "        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
    "        22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
    "        43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
    "        62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84,\n",
    "        85, 86, 87, 88, 89, 90, 92, 93, 95, 100, 107, 109, 112, 118, 119, 122,\n",
    "        125, 128, 130, 133, 138, 141, 144, 145, 147, 148, 149, 151, 154, 155,\n",
    "        156, 159, 161, 166, 168, 171, 175, 176, 177, 178, 180, 181, 184, 185,\n",
    "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
    "        200\n",
    "    ]\n",
    "    MEAN_PIXEL = np.array(\n",
    "        [0.485, 0.456, 0.406], dtype=np.float32).reshape(1, 1, -1)\n",
    "    STD_PIXEL = np.array(\n",
    "        [0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 1, -1)\n",
    "    GRID_SHAPE = 6\n",
    "    IMPULSE_SHAPE = (32, 32)\n",
    "    MIN_PIXELS = 1\n",
    "    MIN_INTERSECTION = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.WIDTH = 32 * self.GRID_SHAPE\n",
    "        self.HEIGHT = 32 * self.GRID_SHAPE\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT, 3)\n",
    "        # 133+1 in panoptic\n",
    "        self.NUM_CLASSES = len(self.CLASS_NAMES)\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T11:12:51.278928Z",
     "start_time": "2018-08-18T11:12:51.259337Z"
    }
   },
   "outputs": [],
   "source": [
    "class CocoDetection(data.Dataset):\n",
    "    def __init__(self, img_dir, seg_dir, ann, config):\n",
    "        self.img_dir = img_dir\n",
    "        self.seg_dir = seg_dir\n",
    "        self.coco_data = self.index_ann(ann)\n",
    "        self.config = config\n",
    "        self.catMap = self.build_class_map()\n",
    "\n",
    "    def index_ann(self, ann):\n",
    "        # create map with coco image index as key\n",
    "        d = {}\n",
    "        for i in ann['annotations']:\n",
    "            coco_index = i['image_id']\n",
    "            d[coco_index] = {'segments_info': i['segments_info'],\n",
    "                             'segments_file': i['file_name'],\n",
    "                             'image_id': i['image_id']}\n",
    "        for i in ann['images']:\n",
    "            coco_index = i['id']\n",
    "            image_file = i['file_name']\n",
    "            d[coco_index]['image_file'] = image_file\n",
    "\n",
    "        return list(d.values())\n",
    "\n",
    "    # coco category ids remapped to contigous range(133+1)\n",
    "    def build_class_map(self):\n",
    "        config = self.config\n",
    "        coco_cat_ids = config.CAT_IDS\n",
    "        catMap = {}\n",
    "        for i in range(config.NUM_CLASSES):\n",
    "            catMap[coco_cat_ids[i]] = i\n",
    "        return catMap\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.load_data(index)\n",
    "        # img, instance_masks, class_ids = self.load_data(index)\n",
    "        # Data Augmentation:\n",
    "        # skip for now\n",
    "\n",
    "        # Target generation:\n",
    "        # return self.generate_targets(img, instance_masks, class_ids)\n",
    "\n",
    "    def load_data(self, index):\n",
    "        coco_data = self.coco_data\n",
    "        config = self.config\n",
    "\n",
    "        ann = coco_data[index]\n",
    "        image_id = ann['image_id']\n",
    "        segments_info = ann['segments_info']\n",
    "        segments_file = ann['segments_file']\n",
    "        image_file = ann['image_file']\n",
    "\n",
    "        img = Image.open(os.path.join(self.img_dir, image_file)).convert('RGB')\n",
    "\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "\n",
    "        coco_seg = Image.open(os.path.join(\n",
    "            self.seg_dir, segments_file)).convert('RGB')\n",
    "        coco_seg = np.array(coco_seg, dtype=np.uint8)\n",
    "        seg_id = self.rgb2id(coco_seg)\n",
    "        \n",
    "        for s in segments_info:\n",
    "            print(s['category_id'])\n",
    "            mask = np.where(seg_id == s['id'], 1, 0)\n",
    "            instance_masks.append(mask)\n",
    "            class_ids.append(self.catMap[s['category_id']])\n",
    "\n",
    "        return np.array(img), np.array(instance_masks), np.array(class_ids)\n",
    "\n",
    "    def rgb2id(self, color):\n",
    "        return color[:, :, 0] + 256 * color[:, :, 1] + 256 * 256 * color[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T11:12:51.507846Z",
     "start_time": "2018-08-18T11:12:51.495798Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ProposalConfig()\n",
    "val_dataset = CocoDetection(val_img_dir, val_seg_dir, val_ann, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T11:12:51.863839Z",
     "start_time": "2018-08-18T11:12:51.697810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "64\n",
      "67\n",
      "72\n",
      "72\n",
      "78\n",
      "82\n",
      "84\n",
      "84\n",
      "85\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "118\n",
      "119\n",
      "130\n",
      "156\n",
      "181\n",
      "186\n",
      "188\n",
      "189\n",
      "199\n",
      "200\n",
      "BG\n",
      "person\n",
      "bicycle\n",
      "car\n",
      "motorcycle\n",
      "airplane\n",
      "bus\n",
      "train\n",
      "truck\n",
      "boat\n",
      "traffic light\n",
      "fire hydrant\n",
      "stop sign\n",
      "parking meter\n",
      "bench\n",
      "bird\n",
      "cat\n",
      "dog\n",
      "horse\n",
      "sheep\n",
      "cow\n",
      "elephant\n",
      "bear\n",
      "zebra\n",
      "giraffe\n",
      "backpack\n",
      "umbrella\n",
      "handbag\n",
      "tie\n",
      "suitcase\n"
     ]
    }
   ],
   "source": [
    "img, instance_masks, class_ids = val_dataset[0]\n",
    "Image.fromarray(img, \"RGB\").show()\n",
    "for i in range(len(instance_masks)):\n",
    "    print(config.CLASS_NAMES[class_ids[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
